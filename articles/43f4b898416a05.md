---
title: "AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ä»®æƒ³ç’°å¢ƒã‚’ç”¨æ„ã™ã‚‹"
emoji: "ğŸ˜º"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["Docker"]
published: false
---

# AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ä»®æƒ³ç’°å¢ƒã‚’æä¾›ã—ãŸã„
OpenAIã®APIã‚’ãŸãŸãå§‹ã‚ã¦ã€OpenAIã®ã‚ˆã†ãªã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½œã‚ŠãŸã„ã¨æ€ã„ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã¦ãã¾ã—ãŸã€‚
ã—ã‹ã—ã€åˆ©ç”¨ã§ãã‚‹æ©Ÿèƒ½ãŒå¢—ãˆã‚‹ã«ã¤ã‚Œã€æ¯å›é€”ä¸­ã§ä½œæ¥­ãŒé€”åˆ‡ã‚Œã‚‹ã®ã¯ã‚‚ã£ãŸã„ãªã„ã¨æ€ã†ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚
ãã‚“ãªæ™‚ã«ã€ŒLinuxã‚’AIãŒãã®ã¾ã¾åˆ©ç”¨ã§ãã‚Œã°ã€ã¨è€ƒãˆãŸã®ã§ã€
å®Ÿéš›ã«ãã®ä»•çµ„ã¿ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ãŒãªã„ã‹èª¿ã¹ã¾ã—ãŸã€‚

# Manusã®ä»•çµ„ã¿
ã€ŒManusã€ã¯å®Ÿéš›ã«ç´ æ™´ã‚‰ã—ã„ã‚µãƒ¼ãƒ“ã‚¹ã§ã™ã€‚è‡ªç¤¾ãƒ¢ãƒ‡ãƒ«ã‚’å±•é–‹ã—ã¦ã„ãªã„ã‚µãƒ¼ãƒ“ã‚¹ã¨ã¯æ€ãˆãªã„ã»ã©ã‚¯ã‚ªãƒªãƒ†ã‚£ãŒé«˜ã„ã§ã™ã€‚


Dockerã¯ã€AIï¼ˆä¾‹: æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚„LLMï¼‰ã®å®Ÿè¡Œç’°å¢ƒã‚’ã‚³ãƒ³ãƒ†ãƒŠåŒ–ã—ã¦ç°¡å˜ã«æ§‹ç¯‰ãƒ»ç®¡ç†ã§ãã‚‹å¼·åŠ›ãªãƒ„ãƒ¼ãƒ«ã§ã™ã€‚ç‰¹ã«ã€ä¾å­˜é–¢ä¿‚ã®è¤‡é›‘ãªAIç’°å¢ƒï¼ˆPythonã€CUDAã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãªã©ï¼‰ã‚’ä¸€è²«ã—ã¦æ‰±ã†ã®ã«é©ã—ã¦ã„ã¾ã™ã€‚

OpenAI APIã‚’ä½¿ã£ãŸAIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆä¾‹: GPT-4oãƒ™ãƒ¼ã‚¹ã®ãƒãƒ£ãƒƒãƒˆã‚„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã¨ã€ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ç’°å¢ƒï¼ˆ`simpleyyt/manus-sandbox` ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ã£ãŸéš”é›¢ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒŠï¼‰ã‚’Dockerã§ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚ã“ã®è¨­å®šã¯ã€AIãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—ã¨ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ï¼ˆä¸€æ™‚çš„ãªå®Ÿè¡Œç’°å¢ƒï¼‰ã‚’æä¾›ã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚

### å‰ææ¡ä»¶
- **OS**: Windows, macOS, ã¾ãŸã¯Linuxï¼ˆæ¨å¥¨: Ubuntu 22.04ä»¥ä¸Šï¼‰ã€‚
- **ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢**: AIå®Ÿè¡Œæ™‚ã¯GPUï¼ˆNVIDIAæ¨å¥¨ï¼‰ãŒã‚ã‚Œã°ä¾¿åˆ©ã§ã™ãŒã€CPUã®ã¿ã§ã‚‚å¯èƒ½ã€‚
- **Dockerã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**: Docker Desktopã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆå…¬å¼ã‚µã‚¤ãƒˆ: https://www.docker.com/products/docker-desktop/ï¼‰ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã€`docker --version` ã§ç¢ºèªã€‚
- **APIã‚­ãƒ¼**: OpenAIã®APIã‚­ãƒ¼ï¼ˆ`API_KEY`ï¼‰ã‚’æº–å‚™ã€‚Googleæ¤œç´¢çµ±åˆã‚’ä½¿ã†å ´åˆã‚‚åŒæ§˜ã€‚
- **æ³¨æ„**: Dockerã¯ãƒªã‚½ãƒ¼ã‚¹ã‚’æ¶ˆè²»ã™ã‚‹ã®ã§ã€ååˆ†ãªRAMï¼ˆ8GBä»¥ä¸Šï¼‰ã¨ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’ç¢ºä¿ã€‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚ã€APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•°ã‚„ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã§ç®¡ç†ã€‚

### ã‚¹ãƒ†ãƒƒãƒ—1: Dockerç’°å¢ƒã®åŸºæœ¬ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
1. **Docker Desktopã‚’èµ·å‹•**: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã€èµ·å‹•ã—ã¦DockerãŒå‹•ä½œã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆ`docker run hello-world` ã§ãƒ†ã‚¹ãƒˆï¼‰ã€‚
2. **ç’°å¢ƒå¤‰æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ**: æä¾›ã•ã‚ŒãŸè¨­å®šã‚’åŸºã«ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆä¾‹: `ai-docker-env`ï¼‰ã‚’ä½œæˆã—ã€`config.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œã‚Šã¾ã™ã€‚
   ```
   # config.env
   API_KEY=your_openai_api_key_here  # å®Ÿéš›ã®ã‚­ãƒ¼ã‚’å…¥åŠ›
   API_BASE=https://api.openai.com/v1
   MODEL_NAME=gpt-4o
   TEMPERATURE=0.7
   MAX_TOKENS=2000

   # Optional search integration (Googleæ¤œç´¢ã‚’ä½¿ã†å ´åˆ)
   GOOGLE_SEARCH_API_KEY=your_google_api_key_here
   GOOGLE_SEARCH_ENGINE_ID=your_search_engine_id_here

   # Sandbox settings
   SANDBOX_IMAGE=simpleyyt/manus-sandbox
   SANDBOX_NAME_PREFIX=sandbox
   SANDBOX_TTL_MINUTES=30
   SANDBOX_NETWORK=manus-network

   # Logging
   LOG_LEVEL=INFO
   ```
   - ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Gitãƒªãƒã‚¸ãƒˆãƒªã«ã‚³ãƒŸãƒƒãƒˆã›ãšã€`.gitignore` ã«è¿½åŠ ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚ï¼‰ã€‚

3. **ã‚«ã‚¹ã‚¿ãƒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½œæˆ**: ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ç”¨ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’äº‹å‰ä½œæˆã€‚
   ```
   docker network create manus-network
   ```

### ã‚¹ãƒ†ãƒƒãƒ—2: AIå®Ÿè¡Œç’°å¢ƒã®Dockerfileä½œæˆ
AIç’°å¢ƒã‚’ã‚³ãƒ³ãƒ†ãƒŠåŒ–ã™ã‚‹ãŸã‚ã«ã€Dockerfileã‚’ä½œæˆã—ã¾ã™ã€‚ã“ã“ã§ã¯ã€Pythonãƒ™ãƒ¼ã‚¹ã®AIã‚¢ãƒ—ãƒªï¼ˆOpenAI APIå‘¼ã³å‡ºã— + ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ç®¡ç†ï¼‰ã‚’æƒ³å®šã€‚`simpleyyt/manus-sandbox` ã¯ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸ãªã®ã§ã€ãã‚Œã‚’ãƒ™ãƒ¼ã‚¹ã«æ‹¡å¼µã€‚

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç½®ãã¾ã™ï¼š
- `Dockerfile`ï¼ˆAIã‚¢ãƒ—ãƒªã®ãƒ“ãƒ«ãƒ‰ç”¨ï¼‰ã€‚
- `app.py`ï¼ˆã‚µãƒ³ãƒ—ãƒ«AIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼‰ã€‚
- `requirements.txt`ï¼ˆä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼‰ã€‚

#### requirements.txt
```
openai==1.12.0  # OpenAI APIç”¨
requests==2.31.0  # HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆç”¨
python-dotenv==1.0.0  # ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ç”¨
```

#### app.pyï¼ˆã‚µãƒ³ãƒ—ãƒ«AIã‚¢ãƒ—ãƒªï¼‰
```python
import os
from dotenv import load_dotenv
from openai import OpenAI
import subprocess
import time
import logging

load_dotenv('config.env')

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=os.getenv('LOG_LEVEL', 'INFO'))
logger = logging.getLogger(__name__)

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = OpenAI(
    api_key=os.getenv('API_KEY'),
    base_url=os.getenv('API_BASE')
)

def query_ai(prompt):
    """AIãƒ¢ãƒ‡ãƒ«ã«ã‚¯ã‚¨ãƒªã‚’é€ä¿¡"""
    model = os.getenv('MODEL_NAME', 'gpt-4o')
    temperature = float(os.getenv('TEMPERATURE', 0.7))
    max_tokens = int(os.getenv('MAX_TOKENS', 2000))
    
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        temperature=temperature,
        max_tokens=max_tokens
    )
    return response.choices[0].message.content

def create_sandbox():
    """ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã‚³ãƒ³ãƒ†ãƒŠã‚’ä½œæˆãƒ»èµ·å‹•"""
    image = os.getenv('SANDBOX_IMAGE', 'simpleyyt/manus-sandbox')
    prefix = os.getenv('SANDBOX_NAME_PREFIX', 'sandbox')
    ttl_minutes = int(os.getenv('SANDBOX_TTL_MINUTES', 30))
    network = os.getenv('SANDBOX_NETWORK', 'manus-network')
    
    container_name = f"{prefix}-{int(time.time())}"
    cmd = [
        'docker', 'run', '-d', '--name', container_name,
        '--network', network, image
    ]
    subprocess.run(cmd)
    logger.info(f"Created sandbox: {container_name}")
    
    # TTLã§è‡ªå‹•åœæ­¢ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    time.sleep(ttl_minutes * 60)
    stop_cmd = ['docker', 'stop', container_name]
    subprocess.run(stop_cmd)
    logger.info(f"Stopped sandbox: {container_name}")

if __name__ == "__main__":
    # ä¾‹: AIã‚¯ã‚¨ãƒªå®Ÿè¡Œ
    prompt = "Hello, AI! Explain Docker briefly."
    ai_response = query_ai(prompt)
    print("AI Response:", ai_response)
    
    # ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ä½œæˆï¼ˆAIå®Ÿè¡Œã®éš”é›¢ç’°å¢ƒã¨ã—ã¦ï¼‰
    create_sandbox()
```

#### Dockerfile
```dockerfile
# ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸: Python 3.10ï¼ˆAIã«é©ã—ãŸè»½é‡ç‰ˆï¼‰
FROM python:3.10-slim

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
WORKDIR /app

# ä¾å­˜ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ã‚¢ãƒ—ãƒªã‚³ãƒ”ãƒ¼
COPY app.py config.env .

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ï¼ˆãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã§config.envã‚’ãƒã‚¦ãƒ³ãƒˆï¼‰
ENV DOTENV_PATH=/app/config.env

# ãƒãƒ¼ãƒˆéœ²å‡ºï¼ˆå¿…è¦ã«å¿œã˜ã¦ã€ä¾‹: 8000ç•ªãƒãƒ¼ãƒˆã§APIã‚µãƒ¼ãƒãƒ¼åŒ–ï¼‰
EXPOSE 8000

# å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰
CMD ["python", "app.py"]
```

### ã‚¹ãƒ†ãƒƒãƒ—3: ã‚³ãƒ³ãƒ†ãƒŠã®ãƒ“ãƒ«ãƒ‰ã¨å®Ÿè¡Œ
1. **ãƒ“ãƒ«ãƒ‰**:
   ```
   docker build -t ai-docker-env .
   ```
   - ã“ã‚Œã§AIç’°å¢ƒã®ã‚¤ãƒ¡ãƒ¼ã‚¸ãŒä½œæˆã•ã‚Œã¾ã™ã€‚

2. **å®Ÿè¡Œ**ï¼ˆç’°å¢ƒå¤‰æ•°ä»˜ãï¼‰:
   ```
   docker run -d --name ai-container \
     --env-file config.env \
     --network manus-network \
     -v $(pwd)/config.env:/app/config.env \
     ai-docker-env
   ```
   - `-d`: ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œã€‚
   - `--env-file`: ç’°å¢ƒå¤‰æ•°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã€‚
   - `-v`: config.env ã‚’ã‚³ãƒ³ãƒ†ãƒŠå†…ã«ãƒã‚¦ãƒ³ãƒˆï¼ˆæ›´æ–°å¯èƒ½ã«ï¼‰ã€‚
   - ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸ã¯è‡ªå‹•ã§`create_sandbox()`ã§ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚

3. **ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹å°‚ç”¨ã‚³ãƒ³ãƒ†ãƒŠã®ãƒ†ã‚¹ãƒˆ**:
   - æä¾›ã•ã‚ŒãŸ`SANDBOX_IMAGE`ã‚’ä½¿ã£ã¦å˜ç‹¬ã§ãƒ†ã‚¹ãƒˆ:
     ```
     docker run -d --name test-sandbox --network manus-network simpleyyt/manus-sandbox
     docker logs test-sandbox  # ãƒ­ã‚°ç¢ºèª
     docker stop test-sandbox  # åœæ­¢
     ```

### ã‚¹ãƒ†ãƒƒãƒ—4: AIç‰¹åŒ–ã®æ‹¡å¼µï¼ˆDocker Model Runneræ¨å¥¨ï¼‰
Dockerå…¬å¼ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ã€ã‚ˆã‚Šé«˜åº¦ãªAIå®Ÿè¡Œç’°å¢ƒã‚’æ§‹ç¯‰ã§ãã¾ã™ï¼ˆ2025å¹´ç¾åœ¨ã®æœ€æ–°æƒ…å ±ã«åŸºã¥ãï¼‰ã€‚Docker Model Runnerã¯ã€Hugging Faceã‚„Docker Hubã®AIãƒ¢ãƒ‡ãƒ«ã‚’ç°¡å˜ã«ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œå¯èƒ½ã«ã—ã¾ã™ã€‚

1. **Docker Model Runnerã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**:
   - Docker Desktopã‚’æœ€æ–°ç‰ˆã«æ›´æ–°ï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³4.30ä»¥ä¸Šï¼‰ã€‚
   - æ‹¡å¼µæ©Ÿèƒ½ã‹ã‚‰ã€ŒDocker Model Runnerã€ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆDocker Dashboard > Extensionsï¼‰ã€‚

2. **AIãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œä¾‹**:
   - Docker Hubã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ—ãƒ«ï¼ˆä¾‹: Llama 3ã‚„Stable Diffusionãªã©ã®äººæ°—ãƒ¢ãƒ‡ãƒ«ï¼‰ã€‚
Raw code

# Docker Model Runnerã‚’æœ‰åŠ¹åŒ–å¾Œã€CLIã§ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œ
docker model run --model meta-llama/llama-3-8b --gpu  # GPUä½¿ç”¨æ™‚
--model: ãƒ¢ãƒ‡ãƒ«åï¼ˆHugging Faceã®IDã‚’æŒ‡å®šï¼‰ã€‚
--gpu: NVIDIA GPUã‚’è‡ªå‹•æ¤œçŸ¥ã—ã¦ä½¿ç”¨ï¼ˆDocker Desktopã®è¨­å®šã§æœ‰åŠ¹åŒ–ï¼‰ã€‚
åˆå›å®Ÿè¡Œæ™‚ã¯ãƒ¢ãƒ‡ãƒ«ãŒè‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã€ã‚³ãƒ³ãƒ†ãƒŠãŒèµ·å‹•ã€‚ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãŒãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ãã¾ã™ï¼ˆé€šå¸¸: http://localhost:8080ï¼‰ã€‚
OpenAI APIã¨ã®çµ±åˆ: ä¸Šè¨˜ã®app.pyã‚’æ‹¡å¼µã—ã¦ã€Model Runnerã§ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã™å ´åˆã€‚

```python
# app.py ã«è¿½åŠ ï¼ˆModel Runnerçµ±åˆä¾‹ï¼‰
def query_local_model(prompt):
    """Docker Model Runnerã§ãƒ­ãƒ¼ã‚«ãƒ«AIãƒ¢ãƒ‡ãƒ«ã‚’ã‚¯ã‚¨ãƒª"""
    # subprocessã§Model Runnerã‚’å‘¼ã³å‡ºã—ï¼ˆAPIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆçµŒç”±ï¼‰
    import requests
    response = requests.post("http://localhost:8080/v1/chat/completions",  # Model Runnerã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
                             json={
                                 "model": "llama-3-8b",
                                 "messages": [{"role": "user", "content": prompt}]
                             })
    return response.json()["choices"][0]["message"]["content"]
```
ã“ã‚Œã§ã‚¯ãƒ©ã‚¦ãƒ‰ä¾å­˜ã‚’æ¸›ã‚‰ã—ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³AIå®Ÿè¡ŒãŒå¯èƒ½ã€‚ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹å†…ã§ãƒ¢ãƒ‡ãƒ«ã‚’éš”é›¢ã—ã¦ãƒ†ã‚¹ãƒˆã€‚
é«˜åº¦ãªè¨­å®šï¼ˆGPUå¯¾å¿œï¼‰:
NVIDIA GPUã‚’ä½¿ã†å ´åˆ: Docker Desktopã®è¨­å®š > Resources > WSL2ï¼ˆWindowsã®å ´åˆï¼‰ã§GPUã‚’æœ‰åŠ¹åŒ–ã€‚NVIDIAãƒ‰ãƒ©ã‚¤ãƒã¨CUDA Toolkitã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆå…¬å¼: https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.htmlï¼‰ã€‚
ã‚³ãƒãƒ³ãƒ‰ä¾‹: docker run --gpus all ai-docker-env ã§GPUã‚’å‰²ã‚Šå½“ã¦ã€‚
Composeãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒãƒ«ãƒã‚³ãƒ³ãƒ†ãƒŠåŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰:
AIã‚¢ãƒ—ãƒª + ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ + ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆä¾‹: Redis for ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ï¼‰ã‚’ä¸€æ‹¬ç®¡ç†ã€‚
docker-compose.yml ã‚’ä½œæˆ:

```yaml
version: '3.8'
services:
  ai-app:
    build: .
    env_file: config.env
    networks:
      - manus-network
    ports:
      - "8000:8000"
    volumes:
      - ./config.env:/app/config.env
  
  sandbox:
    image: simpleyyt/manus-sandbox
    networks:
      - manus-network
    deploy:
      replicas: 1  # è¤‡æ•°ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹å¯èƒ½
  
  redis:  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: çŠ¶æ…‹ç®¡ç†ç”¨
    image: redis:alpine
    networks:
      - manus-network

networks:
  manus-network:
    external: true
å®Ÿè¡Œ: docker-compose up -d 
```
ã§å…¨ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•ã€‚ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªAIç’°å¢ƒãŒå®Œæˆã€‚
